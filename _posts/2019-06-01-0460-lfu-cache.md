---
layout: post
title: 460. LFU Cache
---
### Question
Design and implement a data structure for [Least Frequently Used
(LFU)](https://en.wikipedia.org/wiki/Least_frequently_used) cache. It should
support the following operations: `get` and `put`.

`get(key)` \- Get the value (will always be positive) of the key if the key
exists in the cache, otherwise return -1.  
`put(key, value)` \- Set or insert the value if the key is not already
present. When the cache reaches its capacity, it should invalidate the least
frequently used item before inserting a new item. For the purpose of this
problem, when there is a tie (i.e., two or more keys that have the same
frequency), the least **recently** used key would be evicted.

 **Follow up:**  
Could you do both operations in **O(1)** time complexity?

 **Example:**

    
    
    LFUCache cache = new LFUCache( 2 /* capacity */ );
    
    cache.put(1, 1);
    cache.put(2, 2);
    cache.get(1);       // returns 1
    cache.put(3, 3);    // evicts key 2
    cache.get(2);       // returns -1 (not found)
    cache.get(3);       // returns 3.
    cache.put(4, 4);    // evicts key 1.
    cache.get(1);       // returns -1 (not found)
    cache.get(3);       // returns 3
    cache.get(4);       // returns 4
    

### Solution 1
    
    
     public class LFUCache {
        HashMap<Integer, Integer> vals;
        HashMap<Integer, Integer> counts;
        HashMap<Integer, LinkedHashSet<Integer>> lists;
        int cap;
        int min = -1;
        public LFUCache(int capacity) {
            cap = capacity;
            vals = new HashMap<>();
            counts = new HashMap<>();
            lists = new HashMap<>();
            lists.put(1, new LinkedHashSet<>());
        }
        
        public int get(int key) {
            if(!vals.containsKey(key))
                return -1;
            int count = counts.get(key);
            counts.put(key, count+1);
            lists.get(count).remove(key);
            if(count==min && lists.get(count).size()==0)
                min++;
            if(!lists.containsKey(count+1))
                lists.put(count+1, new LinkedHashSet<>());
            lists.get(count+1).add(key);
            return vals.get(key);
        }
        
        public void set(int key, int value) {
            if(cap<=0)
                return;
            if(vals.containsKey(key)) {
                vals.put(key, value);
                get(key);
                return;
            } 
            if(vals.size() >= cap) {
                int evit = lists.get(min).iterator().next();
                lists.get(min).remove(evit);
                vals.remove(evit);
            }
            vals.put(key, value);
            counts.put(key, 1);
            min = 1;
            lists.get(1).add(key);
        }
    }
    


### Solution 2
## What is my data structure?

### 1\. A Doubly linked Node

    
    
    class Node:
    	+ key: int
    	+ value: int
    	+ freq: int
    	+ prev: Node
    	+ next: Node
    

### 2\. A Doubly Linked List

    
    
    class DLinkedList:
    	- sentinel: Node
    	+ size: int
    	+ append(node: Node) -> None
    	+ pop(node: Node) -> Node
    

### 3\. Our LFUCache

    
    
    class LFUCache:
    	- node: dict[key: int, node: Node]
    	- freq: dict[freq: int, lst: DlinkedList]
    	- minfreq: int
    	+ get(key: int) -> int
    	+ put(key: int, value: int) -> None
    

## Visualization

![image](https://assets.leetcode.com/users/k_kkkyle/image_1545365613.png)

## Explanation

Each key is mapping to the corresponding node (`self._node`), where we can
retrieve the node in `O(1)` time.

Each frequency `freq` is mapped to a Doubly Linked List (`self._freq`), where
all nodes in the `DLinkedList` have the same frequency, `freq`. Moreover, each
node will be always inserted in the head (indicating most recently used).

A minimum frequency `self._minfreq` is maintained to keep track of the minimum
frequency of across all nodes in this cache, such that the DLinkedList with
the min frequency can always be retrieved in O(1) time.

## Here is how the algorithm works

**get(key)**

  1. query the `node` by calling `self._node[key]`
  2. find the frequency by checking `node.freq`, assigned as `f`, and query the `DLinkedList` that this node is in, through calling `self._freq[f]`
  3. pop this node
  4. update node's frequence, append the node to the new `DLinkedList` with frequency `f+1`
  5. if the `DLinkedList` is empty and `self._minfreq == f`, update `self._minfreq` to `f+1`.
  6. return `node.val`

**put(key, value)**

  * If key is already in cache, do the same thing as `get(key)`, and update `node.val` as `value`
  * Otherwise: 
    1. if the cache is full, pop the least frequenly used element (*)
    2. add new node to `self._node`
    3. add new node to `self._freq[1]`
    4. reset `self._minfreq` to 1

(*) The least frequently used element is the **tail element in the DLinkedList
with frequency self._minfreq**

## Implementation

Below is the implementation with detailed comment as well.

    
    
    import collections
    
    class Node:
        def __init__(self, key, val):
            self.key = key
            self.val = val
            self.freq = 1
            self.prev = self.next = None
    
    class DLinkedList:
        """ An implementation of doubly linked list.
    	
    	Two APIs provided:
        
        append(node): append the node to the head of the linked list.
        pop(node=None): remove the referenced node. 
                        If None is given, remove the one from tail, which is the least recently used.
                        
        Both operation, apparently, are in O(1) complexity.
        """
        def __init__(self):
            self._sentinel = Node(None, None) # dummy node
            self._sentinel.next = self._sentinel.prev = self._sentinel
            self._size = 0
        
        def __len__(self):
            return self._size
        
        def append(self, node):
            node.next = self._sentinel.next
            node.prev = self._sentinel
            node.next.prev = node
            self._sentinel.next = node
            self._size += 1
        
        def pop(self, node=None):
            if self._size == 0:
                return
            
            if not node:
                node = self._sentinel.prev
    
            node.prev.next = node.next
            node.next.prev = node.prev
            self._size -= 1
            
            return node
            
    class LFUCache:
        def __init__(self, capacity):
            """
            :type capacity: int
            
            Three things to maintain:
            
            1. a dict, named as `self._node`, for the reference of all nodes given key.
               That is, O(1) time to retrieve node given a key.
               
            2. Each frequency has a doubly linked list, store in `self._freq`, where key
               is the frequency, and value is an object of `DLinkedList`
            
            3. The min frequency through all nodes. We can maintain this in O(1) time, taking
               advantage of the fact that the frequency can only increment by 1. Use the following
    		   two rules:
               
               Rule 1: Whenever we see the size of the DLinkedList of current min frequency is 0,
                       the min frequency must increment by 1.
               
               Rule 2: Whenever put in a new (key, value), the min frequency must 1 (the new node)
               
            """
            self._size = 0
            self._capacity = capacity
            
            self._node = dict() # key: Node
            self._freq = collections.defaultdict(DLinkedList)
            self._minfreq = 0
            
            
        def _update(self, node):
            """ 
            This is a helper function that used in the following two cases:
            
                1. when `get(key)` is called; and
                2. when `put(key, value)` is called and the key exists.
             
            The common point of these two cases is that:
            
                1. no new node comes in, and
                2. the node is visited one more times -> node.freq changed -> 
                   thus the place of this node will change
            
            The logic of this function is:
            
                1. pop the node from the old DLinkedList (with freq `f`)
                2. append the node to new DLinkedList (with freq `f+1`)
                3. if old DlinkedList has size 0 and self._minfreq is `f`,
                   update self._minfreq to `f+1`
            
            All of the above opeartions took O(1) time.
            """
            freq = node.freq
            
            self._freq[freq].pop(node)
            if self._minfreq == freq and not self._freq[freq]:
                self._minfreq += 1
            
            node.freq += 1
            freq = node.freq
            self._freq[freq].append(node)
        
        def get(self, key):
            """
            Through checking self._node[key], we can get the node in O(1) time.
            Just performs self._update, then we can return the value of node.
            
            :type key: int
            :rtype: int
            """
            if key not in self._node:
                return -1
            
            node = self._node[key]
            self._update(node)
            return node.val
    
        def put(self, key, value):
            """
            If `key` already exists in self._node, we do the same operations as `get`, except
            updating the node.val to new value.
            
            Otherwise, the following logic will be performed
            
            1. if the cache reaches its capacity, pop the least frequently used item. (*)
            2. add new node to self._node
            3. add new node to the DLinkedList with frequency 1
            4. reset self._minfreq to 1
            
            (*) How to pop the least frequently used item? Two facts:
            
            1. we maintain the self._minfreq, the minimum possible frequency in cache.
            2. All cache with the same frequency are stored as a DLinkedList, with
               recently used order (Always append at head)
              
            Consequence? ==> The tail of the DLinkedList with self._minfreq is the least
                             recently used one, pop it...
            
            :type key: int
            :type value: int
            :rtype: void
            """
            if self._capacity == 0:
                return
            
            if key in self._node:
                node = self._node[key]
                self._update(node)
                node.val = value
            else:
                if self._size == self._capacity:
                    node = self._freq[self._minfreq].pop()
                    del self._node[node.key]
                    self._size -= 1
                    
                node = Node(key, value)
                self._node[key] = node
                self._freq[1].append(node)
                self._minfreq = 1
                self._size += 1
    


### Solution 3
Two HashMaps are used, one to store <key, value> pair, another store the <key,
node>.  
I use double linked list to keep the frequent of each key. In each double
linked list node, keys with the same count are saved using java built in
LinkedHashSet. This can keep the order.  
Every time, one key is referenced, first find the current node corresponding
to the key, If the following node exist and the frequent is larger by one, add
key to the keys of the following node, else create a new node and add it
following the current node.  
All operations are guaranteed to be O(1).

    
    
    public class LFUCache {
        private Node head = null;
        private int cap = 0;
        private HashMap<Integer, Integer> valueHash = null;
        private HashMap<Integer, Node> nodeHash = null;
        
        public LFUCache(int capacity) {
            this.cap = capacity;
            valueHash = new HashMap<Integer, Integer>();
            nodeHash = new HashMap<Integer, Node>();
        }
        
        public int get(int key) {
            if (valueHash.containsKey(key)) {
                increaseCount(key);
                return valueHash.get(key);
            }
            return -1;
        }
        
        public void set(int key, int value) {
            if ( cap == 0 ) return;
            if (valueHash.containsKey(key)) {
                valueHash.put(key, value);
            } else {
                if (valueHash.size() < cap) {
                    valueHash.put(key, value);
                } else {
                    removeOld();
                    valueHash.put(key, value);
                }
                addToHead(key);
            }
            increaseCount(key);
        }
        
        private void addToHead(int key) {
            if (head == null) {
                head = new Node(0);
                head.keys.add(key);
            } else if (head.count > 0) {
                Node node = new Node(0);
                node.keys.add(key);
                node.next = head;
                head.prev = node;
                head = node;
            } else {
                head.keys.add(key);
            }
            nodeHash.put(key, head);      
        }
        
        private void increaseCount(int key) {
            Node node = nodeHash.get(key);
            node.keys.remove(key);
            
            if (node.next == null) {
                node.next = new Node(node.count+1);
                node.next.prev = node;
                node.next.keys.add(key);
            } else if (node.next.count == node.count+1) {
                node.next.keys.add(key);
            } else {
                Node tmp = new Node(node.count+1);
                tmp.keys.add(key);
                tmp.prev = node;
                tmp.next = node.next;
                node.next.prev = tmp;
                node.next = tmp;
            }
    
            nodeHash.put(key, node.next);
            if (node.keys.size() == 0) remove(node);
        }
        
        private void removeOld() {
            if (head == null) return;
            int old = 0;
            for (int n: head.keys) {
                old = n;
                break;
            }
            head.keys.remove(old);
            if (head.keys.size() == 0) remove(head);
            nodeHash.remove(old);
            valueHash.remove(old);
        }
        
        private void remove(Node node) {
            if (node.prev == null) {
                head = node.next;
            } else {
                node.prev.next = node.next;
            } 
            if (node.next != null) {
                node.next.prev = node.prev;
            }
        }
        
        class Node {
            public int count = 0;
            public LinkedHashSet<Integer> keys = null;
            public Node prev = null, next = null;
            
            public Node(int count) {
                this.count = count;
                keys = new LinkedHashSet<Integer>();
                prev = next = null;
            }
        }
    }



